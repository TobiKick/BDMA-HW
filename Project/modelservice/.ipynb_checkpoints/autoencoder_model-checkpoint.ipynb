{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# import keras\n",
    "# from keras.models import Model, Sequential\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "# from keras.layers import Dense, BatchNormalization, Dropout, Flatten, Input, GaussianNoise\n",
    "import tensorflow as tf\n",
    "# from keras import regularizers, backend as K\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers, backend as K\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "\n",
    "import mlflow.keras\n",
    "import mlflow\n",
    "mlflow.keras.autolog()\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED) # NumPy\n",
    "random.seed(RANDOM_SEED) # Python\n",
    "tf.set_random_seed(RANDOM_SEED) # Tensorflow\n",
    "\n",
    "LABELS = [\"Normal\", \"Fraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/pawelurbanowicz/master-thesis/data/'\n",
    "\n",
    "identities = pd.read_csv(f'{folder_path}train_identity.csv')\n",
    "txs = pd.read_csv(f'{folder_path}train_transaction.csv')\n",
    "\n",
    "train = pd.merge(txs, identities, on='TransactionID', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data exploration \n",
    "\n",
    "### Transaction\n",
    "\n",
    "Features:\n",
    "* TransactionID - unique id \n",
    "* isFraud - value to predict\n",
    "* TransactionDT - timedelta from a given reference datetime (not an actual timestamp)\n",
    "* TransactionAmt - amount in USD\n",
    "* dist1,dist2 - distance\n",
    "* C1 ... C14 - counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked\n",
    "* D1 ... D15 - timedelta, such as days between previous transaction\n",
    "* V1 ... V339 - vesta engineered rich features\n",
    "\n",
    "Categorical features: \n",
    "* ProductCD - product code \n",
    "* P_emaildomain,R_emaildomain - purchaser and recipient email domain\n",
    "* card1 ... card6 - payment card information\n",
    "* addr1,addr2 - address(region, country)\n",
    "* M1 ... M9 - match, such as names on card and address\n",
    "\n",
    "### Identities\n",
    "Contians information realtead to transaction as network connection information,digital signature, device rating,ip_doamin rating, proxy rating, account login times, failed logins, time spend on page,\n",
    "\n",
    "Features:\n",
    "* TransactionID\n",
    "* id_01 ... id_11 - numerical features\n",
    "\n",
    "Categorical features:\n",
    "* id_12 ... id_38\n",
    "* DeviceType\n",
    "* DeviceInfo\n",
    "\n",
    "https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203#latest-671062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "base_features = ['TransactionID', 'isFraud', 'TransactionDT']\n",
    "\n",
    "c_counting_features = ['C' + str(n) for n in range(1,15)]\n",
    "d_timedelta_features = ['D' + str(n) for n in range(1,16)]\n",
    "id_numerical_features = ['id_0' + str(n) for n in range(1,10)] + ['id_10', 'id_11']\n",
    "numerical_features = ['TransactionAmt', 'dist1', 'dist2'] + c_counting_features + d_timedelta_features + id_numerical_features \n",
    "\n",
    "vesta_features = ['V' + str(n) for n in range(1,340)]\n",
    "\n",
    "# categorical features\n",
    "m_features = ['M' + str(n) for n in range(1,10)]\n",
    "card_features = ['card' + str(n) for n in range(1,7)]\n",
    "id_categorical_features = ['id_' + str(n) for n in range(12,39)]\n",
    "categorical_features = ['ProductCD','P_emaildomain','R_emaildomain', 'addr1','addr2', 'DeviceType', 'DeviceInfo'] + m_features + card_features + id_categorical_features\n",
    "\n",
    "# all features\n",
    "all_features = base_features + numerical_features + vesta_features + categorical_features\n",
    "\n",
    "# train = train[base_features + categorical_features + numerical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (590540, 434)\n",
      "Number of fraud txs:  20663\n",
      "Number of normal txs:  569877\n",
      "Procentage of fraud txs:  3.4990009144173126\n"
     ]
    }
   ],
   "source": [
    "frauds = train[train.isFraud == 1]\n",
    "normal = train[train.isFraud == 0]\n",
    "print('Shape: ', train.shape)\n",
    "print(\"Number of fraud txs: \", len(frauds))\n",
    "print(\"Number of normal txs: \", len(normal))\n",
    "print(\"Procentage of fraud txs: \", len(frauds)/len(train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "\n",
       "   card2  card3       card4  card5  ... id_31  id_32  id_33  id_34  id_35  \\\n",
       "0    NaN  150.0    discover  142.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
       "2  490.0  150.0        visa  166.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "  id_36 id_37  id_38  DeviceType  DeviceInfo  \n",
       "0   NaN   NaN    NaN         NaN         NaN  \n",
       "1   NaN   NaN    NaN         NaN         NaN  \n",
       "2   NaN   NaN    NaN         NaN         NaN  \n",
       "\n",
       "[3 rows x 434 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionAmt     0.00\n",
       "dist1             59.65\n",
       "dist2             93.63\n",
       "C1                 0.00\n",
       "C2                 0.00\n",
       "C3                 0.00\n",
       "C4                 0.00\n",
       "C5                 0.00\n",
       "C6                 0.00\n",
       "C7                 0.00\n",
       "C8                 0.00\n",
       "C9                 0.00\n",
       "C10                0.00\n",
       "C11                0.00\n",
       "C12                0.00\n",
       "C13                0.00\n",
       "C14                0.00\n",
       "D1                 0.21\n",
       "D2                47.55\n",
       "D3                44.51\n",
       "D4                28.60\n",
       "D5                52.47\n",
       "D6                87.61\n",
       "D7                93.41\n",
       "D8                87.31\n",
       "D9                87.31\n",
       "D10               12.87\n",
       "D11               47.29\n",
       "D12               89.04\n",
       "D13               89.51\n",
       "D14               89.47\n",
       "D15               15.09\n",
       "id_01             75.58\n",
       "id_02             76.15\n",
       "id_03             88.77\n",
       "id_04             88.77\n",
       "id_05             76.82\n",
       "id_06             76.82\n",
       "id_07             99.13\n",
       "id_08             99.13\n",
       "id_09             87.31\n",
       "id_10             87.31\n",
       "id_11             76.13\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[numerical_features].isnull().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ProductCD</th>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_emaildomain</th>\n",
       "      <td>15.99</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_emaildomain</th>\n",
       "      <td>76.75</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr1</th>\n",
       "      <td>11.13</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr2</th>\n",
       "      <td>11.13</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceType</th>\n",
       "      <td>76.16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceInfo</th>\n",
       "      <td>79.91</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M1</th>\n",
       "      <td>45.91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M2</th>\n",
       "      <td>45.91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M3</th>\n",
       "      <td>45.91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M4</th>\n",
       "      <td>47.66</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M5</th>\n",
       "      <td>59.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M6</th>\n",
       "      <td>28.68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M7</th>\n",
       "      <td>58.64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M8</th>\n",
       "      <td>58.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M9</th>\n",
       "      <td>58.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>13553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card2</th>\n",
       "      <td>1.51</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card3</th>\n",
       "      <td>0.27</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card4</th>\n",
       "      <td>0.27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card5</th>\n",
       "      <td>0.72</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card6</th>\n",
       "      <td>0.27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_12</th>\n",
       "      <td>75.58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_13</th>\n",
       "      <td>78.44</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_14</th>\n",
       "      <td>86.45</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_15</th>\n",
       "      <td>76.13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_16</th>\n",
       "      <td>78.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_17</th>\n",
       "      <td>76.40</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_18</th>\n",
       "      <td>92.36</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>76.41</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_20</th>\n",
       "      <td>76.42</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_21</th>\n",
       "      <td>99.13</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_22</th>\n",
       "      <td>99.12</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_23</th>\n",
       "      <td>99.12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_24</th>\n",
       "      <td>99.20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_25</th>\n",
       "      <td>99.13</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_26</th>\n",
       "      <td>99.13</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_27</th>\n",
       "      <td>99.12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_28</th>\n",
       "      <td>76.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_29</th>\n",
       "      <td>76.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_30</th>\n",
       "      <td>86.87</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_31</th>\n",
       "      <td>76.25</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_32</th>\n",
       "      <td>86.86</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_33</th>\n",
       "      <td>87.59</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_34</th>\n",
       "      <td>86.82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_35</th>\n",
       "      <td>76.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_36</th>\n",
       "      <td>76.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_37</th>\n",
       "      <td>76.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_38</th>\n",
       "      <td>76.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0      1\n",
       "ProductCD       0.00      5\n",
       "P_emaildomain  15.99     59\n",
       "R_emaildomain  76.75     60\n",
       "addr1          11.13    332\n",
       "addr2          11.13     74\n",
       "DeviceType     76.16      2\n",
       "DeviceInfo     79.91   1786\n",
       "M1             45.91      2\n",
       "M2             45.91      2\n",
       "M3             45.91      2\n",
       "M4             47.66      3\n",
       "M5             59.35      2\n",
       "M6             28.68      2\n",
       "M7             58.64      2\n",
       "M8             58.63      2\n",
       "M9             58.63      2\n",
       "card1           0.00  13553\n",
       "card2           1.51    500\n",
       "card3           0.27    114\n",
       "card4           0.27      4\n",
       "card5           0.72    119\n",
       "card6           0.27      4\n",
       "id_12          75.58      2\n",
       "id_13          78.44     54\n",
       "id_14          86.45     25\n",
       "id_15          76.13      3\n",
       "id_16          78.10      2\n",
       "id_17          76.40    104\n",
       "id_18          92.36     18\n",
       "id_19          76.41    522\n",
       "id_20          76.42    394\n",
       "id_21          99.13    490\n",
       "id_22          99.12     25\n",
       "id_23          99.12      3\n",
       "id_24          99.20     12\n",
       "id_25          99.13    341\n",
       "id_26          99.13     95\n",
       "id_27          99.12      2\n",
       "id_28          76.13      2\n",
       "id_29          76.13      2\n",
       "id_30          86.87     75\n",
       "id_31          76.25    130\n",
       "id_32          86.86      4\n",
       "id_33          87.59    260\n",
       "id_34          86.82      4\n",
       "id_35          76.13      2\n",
       "id_36          76.13      2\n",
       "id_37          76.13      2\n",
       "id_38          76.13      2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = train[categorical_features].nunique()\n",
    "nan_values = train[categorical_features].isnull().mean().round(4) * 100\n",
    "\n",
    "values = pd.concat([nan_values, unique_values], axis=1)\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation\n",
    "\n",
    "https://www.kaggle.com/abazdyrev/keras-nn-focal-loss-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud'].to_numpy()\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tranformers import drop_columns, CategoricalTransformer, NumericalTransformer\n",
    "\n",
    "\n",
    "def get_categories(df, n_values = 10):\n",
    "    categories = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        categories.append(list(df[column].value_counts().iloc[: n_values - 1].index) + ['other'])\n",
    "        \n",
    "    return categories\n",
    "\n",
    "categories = get_categories(X[categorical_features])\n",
    "\n",
    "categorical_pipe = make_pipeline(\n",
    "    CategoricalTransformer(categories), \n",
    "    OneHotEncoder(categories = categories, sparse = False )\n",
    ")\n",
    "\n",
    "numerical_pipe = make_pipeline(\n",
    "    NumericalTransformer(), \n",
    "    StandardScaler(), \n",
    "    SimpleImputer(strategy='constant', fill_value=0, missing_values=np.nan)\n",
    ")\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "    (FunctionTransformer(drop_columns), ['TransactionDT', 'TransactionID'] + vesta_features),\n",
    "    (categorical_pipe, categorical_features),\n",
    "    (numerical_pipe, numerical_features),\n",
    "    remainder ='passthrough'\n",
    ")\n",
    "\n",
    "X = transformer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model building\n",
    "\n",
    "Based on https://arxiv.org/pdf/1908.11553.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472432, 365)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/10\n",
      "472432/472432 [==============================] - 86s 183us/sample - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0309 - val_mean_squared_error: 0.0309\n",
      "Epoch 2/10\n",
      "472432/472432 [==============================] - 92s 194us/sample - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.0290 - val_mean_squared_error: 0.0290\n",
      "Epoch 3/10\n",
      "472432/472432 [==============================] - 39s 83us/sample - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0281 - val_mean_squared_error: 0.0281\n",
      "Epoch 4/10\n",
      "472432/472432 [==============================] - 49s 104us/sample - loss: 0.0278 - mean_squared_error: 0.0278 - val_loss: 0.0277 - val_mean_squared_error: 0.0277\n",
      "Epoch 5/10\n",
      "472432/472432 [==============================] - 86s 182us/sample - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0273 - val_mean_squared_error: 0.0273\n",
      "Epoch 6/10\n",
      "472432/472432 [==============================] - 68s 144us/sample - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
      "Epoch 7/10\n",
      "472432/472432 [==============================] - 100s 211us/sample - loss: 0.0269 - mean_squared_error: 0.0269 - val_loss: 0.0268 - val_mean_squared_error: 0.0268\n",
      "Epoch 8/10\n",
      "206720/472432 [============>.................] - ETA: 34s - loss: 0.0265 - mean_squared_error: 0.0265"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "def build_autoencoder():\n",
    "    \n",
    "    Hidden_layer = 200\n",
    "    model = keras.Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    \n",
    "    model.add(Dense(Hidden_layer, activation='tanh'))\n",
    "    model.add(Dense(Hidden_layer/2, activation='tanh'))\n",
    "    model.add(Dense(Hidden_layer/4, activation='tanh'))\n",
    "    \n",
    "    model.add(Dense(Hidden_layer/4, activation='tanh'))\n",
    "    model.add(Dense(Hidden_layer/2, activation='tanh'))\n",
    "    model.add(Dense(Hidden_layer, activation='tanh'))\n",
    "    model.add(Dense(X_train.shape[1], activation='tanh'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=['mse']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_autoencoder()\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train, \n",
    "    y=X_train, \n",
    "    validation_data=(X_test, X_test), \n",
    "    epochs=EPOCHS,\n",
    "    shuffle=True,\n",
    "    batch_size=128).history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = model.predict(X_train)\n",
    "X_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(Dense(100, activation='tanh'))\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(Dense(50, activation='tanh'))\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(Dense(25, activation='tanh'))\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['acc']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=EPOCHS,\n",
    "    shuffle=True,\n",
    "    batch_size=128).history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "* Confusion matrix, precision, recall and F1\n",
    "* ROC and AUROC\n",
    "\n",
    "Accuracy is misleading for this dateset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.3)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"Test Data Accuracy:\", score)\n",
    "\n",
    "stats = precision_recall_fscore_support(y_test, y_pred)\n",
    "mlflow.log_metric(\"precision 1\", stats[0][1])\n",
    "mlflow.log_metric(\"recall 1\", stats[1][1])\n",
    "mlflow.log_metric(\"f1-score 1\", stats[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (4,4))\n",
    "\n",
    "sns.heatmap(df_cm, annot=True, fmt='g', xticklabels=LABELS, yticklabels=LABELS)\n",
    "\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()\n",
    "\n",
    "mlflow.log_metric(\"Tnormal-Pnormal\", cm[0][0])\n",
    "mlflow.log_metric(\"Tnormal-Pfraud\", cm[0][1])\n",
    "mlflow.log_metric(\"Tfraud-Pnormal\", cm[1][0])\n",
    "mlflow.log_metric(\"Tfraud-Pfraud\", cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "y_pred = model.predict(X_test).ravel()\n",
    "fpr, tpr, thresholds_keras = roc_curve(y_test, y_pred)\n",
    "auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Auc area = {:.4f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "mlflow.log_metric(\"auc\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = keras.Sequential()\n",
    "    \n",
    "#     dropout_min  =  0\n",
    "#     dropout_max  =  0.6\n",
    "#     dropout_step =  0.1\n",
    "    \n",
    "#     for i in range(hp.Int('num_layers', 2, 10)):\n",
    "#         model.add(Dense(units=hp.Int('units' + str(i), min_value=32, max_value=512, step=32), activation='relu'))\n",
    "#         model.add(Dropout( hp.Float('dropout'+ str(i),min_value=0,max_value=0.5,step=0.1) ) )\n",
    "        \n",
    "#     model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     model.compile(\n",
    "#         optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[1e-2, 1e-3, 1e-4])),\n",
    "#         loss=\"binary_crossentropy\",\n",
    "#         metrics=['acc']\n",
    "#     )\n",
    "#     return model\n",
    "\n",
    "# tuner = RandomSearch(\n",
    "#     build_model,\n",
    "#     objective='acc',\n",
    "#     max_trials=15,\n",
    "#     executions_per_trial=3,\n",
    "#     directory='my_dir',\n",
    "#     project_name='helloworld')\n",
    "\n",
    "# tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search_space_summary()\n",
    "# models = tuner.get_best_models(num_models=2)\n",
    "# tuner.results_summary()\n",
    "# print(tuner.get_best_hyperparameters()[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os \n",
    "\n",
    "current_dir = os.path.abspath('')\n",
    "transformer_path = \"data_transformer.joblib\"\n",
    "\n",
    "joblib.dump(transformer, transformer_path)\n",
    "\n",
    "mlflow.keras.log_model(model, '')\n",
    "mlflow.log_artifact(transformer_path, 'data')\n",
    "mlflow.log_artifact(os.path.abspath('') + '/keras_model.ipynb')\n",
    "\n",
    "os.remove(current_dir + '/' + transformer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. References "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis:\n",
    "https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd\n",
    "    \n",
    "https://www.kaggle.com/tarunpaparaju/how-to-survive-the-shakeup-don-t-overfit\n",
    "left on Ensembling\n",
    "\n",
    "\n",
    "IDEAS:\n",
    "    * check identity tabel\n",
    "    * improve data preperation\n",
    "    * categorical_features encoding using embedding\n",
    "    * autoencoders\n",
    "    * split data in a way that we only train on normal txs\n",
    "    * Ensembling\n",
    "    * oversampling/undersampling smoth\n",
    "    * K-fold Cross-Validation \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
